---
title: 'Stat 415 Regression: Homework 1'
author: "Frankie Tyndall"
date: '2022-07-03'
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(broom)
library(dplyr)
gpaact <- read_csv("C:/Users/frank/Downloads/gpaact.csv")
```

## Grade point average Dataset

The director of admissions of a small college selected 120 students at
random from the new freshman class in a study to determine whether a student's grade point average (GPA) at the end of the freshman year (Y) can be predicted from the ACT test score (X).The results of the study follow. Assume that first-order regression model is appropriate.

x is the ACT test score
Y is grade point average (GPA) at the end of the freshman year

```{r}
gpaact




```

## Obtain the least squares estimates of Bo and B1 and state the estimated regression function.


```{r}
lm(gpaact$gpa ~ gpaact$actscore)
```
Bo = y intercept = 2.11405
B1 = slope = 0.03883
y(hat) = Bo + B1x
y(hat) = 2.11405 + 0.03883x

##  Plot the estimated regression function and the scatter plot. Does the estimated regression function appear to fit the data well?
```{r}
qplot(x = actscore, y = gpa, data = gpaact, geom = "point") +
  geom_smooth(method = lm, se = FALSE)

gpaact.out <- lm(gpaact$gpa ~ gpaact$actscore)
summary(gpaact.out)


cor(gpaact$gpa, gpaact$actscore)

```
Based on the scatter plot above, it looks like there is a moderately positive linear relationship between the two quantitative variables. The points seem somewhat clustered about the fitted regression line. The estimated regression function is y(hat) = 2.11405 + 0.03883x and the p value of the predictor variable (actscore) is 0.00292 which is below the 0.05 threshold rejecting the null hypothesis that the theoritical slope is equal to 0. The multiple R squared is 0.07262. The correlation coefficient is 0.2694818 which shows a weak
relationship between the gpa and act scores. This regression model/
function does not seem to fit the data well. There seems to be extreme
outliers which could be having a neagtive impact on the ability for 
the model to predict.


## Give a full interpretation of the slope for the regression function that you generated in part a.

Bo = y intercept = 2.11405
B1 = slope = 0.03883
y(hat) = Bo + B1x
y(hat) = 2.11405 + 0.03883x

The slope indicates that for every increase by 1 point in act score,
the grade point average (GPA) at the end of the freshman year increases by
0.03883 point on average.

## Obtain a point estimate of the mean freshman GPA for students with ACT test score X = 28

y(hat) = Bo + B1x
y(hat) = 2.11405 + 0.03883x
y(hat) = 2.11405 + 0.03883(28)
y(hat) = 3.20129

## As demonstrated in class, use R coding to produce a regression output summary table and indicate the typical distance between the sample slope estimate and the true population slope estimate. Also, fine the proportion of variability in the response variable that is explained by your regression model.

```{r}

gpaact.out <- lm(gpaact$gpa ~ gpaact$actscore)
summary(gpaact.out)



```
The typical distance between a sampled slope estimate and the true slope from the population is called the standard error of slope which is 0.01277. The proportion of variability in the response variable is the multiple r-squared
which is 0.07262. This means that 7.262% of the variation in the response variable (GPA) can be explained by the regression model with the predictor variable (actscore). 

##  Find the residual for X = 28, and determine if the observed value is above or below average.

```{r}
observed_for28 <- gpaact%>% filter(actscore == 28)
observed_for28




```

y(hat) = Bo + B1x
y(hat) = 2.11405 + 0.03883x
y(hat) = 2.11405 + 0.03883(28)
y(hat) = expected value = 3.20129

residual = observed - expected
residual = 3.778 - 3.20129 = 0.57671. Being that the residual is positive
this means that the observed value of 3.778 is above average or above the
fitted line. 


## As demonstrated in class, use R coding to find a 95% confidence interval for B1


```{r}
confidence_B1 <- lm(gpaact$gpa ~ gpaact$actscore)
confidence_B1

confidence_B1_1 <- tidy(confidence_B1, conf.int = TRUE)
select(confidence_B1_1, term, estimate, p.value, conf.low, conf.high)



```
We are 95% confident that the true population slope falls between 0.01353307 and 0.06412118

## As demonstrated in class, use R coding to find a 95% confidence interval for an input value of  X = 28.


```{r}
confidence_y <- lm(gpaact$gpa ~ gpaact$actscore)
confidence_y

new_df <- data.frame(actscore = 28)
new_df

predict(object = confidence_y, newdata = new_df, interval = "confidence") %>%
cbind(new_df)

```
## Find an estimate for the variance of the population regression function

```{r}
# n = 120
# degrees of freedom = n - 2 
#                    = 120 - 2 = 118

gpplt <- gpaact
anova(lm(gpplt$gpa ~ gpplt$actscore))



```
The estimated variance of the population regression function is 0.3883 

## Refer to regression model above, what is the implication for the regression function if B1 = 0 so that the model is Yi = B0 + ei? How would the regression function plot on a graph? Provide a detailed answer of 5 or 6 sentences.

B1 equaling 0 would mean that the slope is 0 indicating that the predictor and
response variable do not have a linear relationship and that the predictor variable (X) does not fit as predictor of the distribution of the response variable (Y). A A zero slope is just the slope of a horizontal line! This indicates that y coordinate never changes no matter what the x coordinate. A slope of zero would mean that your regression line would be perfectly horizontal. If the slope is zero, then no x will be put into the regression model so you are left with B0 which is the y intercept and ei which is the residual. 


## Again using the regression model above, Is it true or false that the model always produces a data point that is exactly on the regression line regardless of the value of the error term?  Justify your answer.

This statement is false because the equation, Yi = B(0) + b(1)X(i) without the inclusion of the error value is what produces data points that are exactly on the regression line for an X input. The equation, Yi = B(0) + B(1)X(i) + E(i), produces data points that may or may not be on the regression line for an X input value and a given error value. So saying that the points will alway be on 
the regression line, regardless of the error value is false, making the
statement not true.





